{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/OPnitesh/PYTORCH.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIRLdnx_AXFL",
        "outputId": "87ab3a2a-bf10-4b86-a51d-08155de8b6fc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PYTORCH'...\n",
            "warning: You appear to have cloned an empty repository.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "80YmV5BjATXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1=torch.tensor(4.)\n",
        "t1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkTPbC9fwKyE",
        "outputId": "833e1e2e-2614-496d-db37-75d675b829dc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Onvr7uA5yxv",
        "outputId": "154547d7-44b0-474d-f029-8b46e0e2eded"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vector\n",
        "t2=torch.tensor([1.,2,3,4])\n",
        "t2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncZ4yO8r501V",
        "outputId": "da4ea76b-795d-4823-c071-de327c138a38"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4.])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#matrix\n",
        "t3=torch.tensor([[5.,6.],\n",
        "                [7.,8.],\n",
        "                 [9.,10.]])\n",
        "t3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvi8Wix15_US",
        "outputId": "e68470e5-245b-46db-a05b-3a2f25bd5539"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  6.],\n",
              "        [ 7.,  8.],\n",
              "        [ 9., 10.]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3d-dimensional\n",
        "t4=torch.tensor([\n",
        "                  [[11,12,13],\n",
        "                  [13,14,15]],\n",
        "                  [[15,16,17],\n",
        "                  [17,18,19]]])\n",
        "t4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aljEE3_96UJY",
        "outputId": "e54d926f-343c-4337-91b8-0d2ed3f5279c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[11, 12, 13],\n",
              "         [13, 14, 15]],\n",
              "\n",
              "        [[15, 16, 17],\n",
              "         [17, 18, 19]]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu0WWw5U675R",
        "outputId": "6b547cd8-80ce-42af-ef4c-4b3a7b218a60"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t3.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e83BlU437S8S",
        "outputId": "0ebd3716-b466-4d5c-9ecd-6369c9bc9f72"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t4.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5k-UKa8Q7XAO",
        "outputId": "08247a72-9d5c-4919-8966-43a40ff5587f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor operation and gradient"
      ],
      "metadata": {
        "id": "P3Xdi4_29OBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## create tensors.\n",
        "x = torch.tensor(3.)\n",
        "w = torch.tensor(4., requires_grad=True)\n",
        "b = torch.tensor(5., requires_grad=True)\n",
        "x, w, b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyUmD3Xh7Zss",
        "outputId": "cd524979-27af-4dab-bd9f-1d4d463b890a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have created three tensor: x w b all number w and b have an additional parameters require_grad set to true."
      ],
      "metadata": {
        "id": "x5B2e6e79z4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets create a new tensor y by combinning these tensors"
      ],
      "metadata": {
        "id": "JSkwFOO8-DhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y=w*x+b\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVMXa_Fb9rcn",
        "outputId": "d0cc193d-21e8-4757-9140-b1bf7f05211c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17., grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the derivative\n",
        "y.backward()"
      ],
      "metadata": {
        "id": "B1cupgu9-MhZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## display the gradient\n",
        "print('dy/dx', x.grad) ## it getting none becz it does't hold the gradient=true.\n",
        "print('dy/dw', w.grad)\n",
        "print('dy/db', b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl6OLEzO-wj_",
        "outputId": "818b13f6-9ac2-48a6-f886-9ca74f7f5ec0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dy/dx None\n",
            "dy/dw tensor(3.)\n",
            "dy/db tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor Function"
      ],
      "metadata": {
        "id": "NLalocDL_xyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t6=torch.full([3,2], 42)\n",
        "t6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfEZUis9_GX9",
        "outputId": "43584f28-8400-47e2-d68e-9bb352fd484c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[42, 42],\n",
              "        [42, 42],\n",
              "        [42, 42]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Z_WW4hVTBJa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## concate the tensors with the two compatible shapes\n",
        "t7=torch.cat([t3,t6])\n",
        "t7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9YxjU9fBDA7",
        "outputId": "24566b08-c73e-4808-a98f-da43d5ff6017"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  6.],\n",
              "        [ 7.,  8.],\n",
              "        [ 9., 10.],\n",
              "        [42., 42.],\n",
              "        [42., 42.],\n",
              "        [42., 42.]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compute the sin of each element\n",
        "t8=torch.sin(t7)\n",
        "t8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5eyal3dBfaw",
        "outputId": "1b996022-3db7-4e5f-9725-abee351d34cd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9589, -0.2794],\n",
              "        [ 0.6570,  0.9894],\n",
              "        [ 0.4121, -0.5440],\n",
              "        [-0.9165, -0.9165],\n",
              "        [-0.9165, -0.9165],\n",
              "        [-0.9165, -0.9165]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## change the shape of tensors\n",
        "t9=t8.reshape(2,3,2)\n",
        "t9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdK56xJ4Bs37",
        "outputId": "e64f0761-6d02-424e-8371-6e3b5c73b257"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.9589, -0.2794],\n",
              "         [ 0.6570,  0.9894],\n",
              "         [ 0.4121, -0.5440]],\n",
              "\n",
              "        [[-0.9165, -0.9165],\n",
              "         [-0.9165, -0.9165],\n",
              "         [-0.9165, -0.9165]]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear-regression from scratch using pytorch"
      ],
      "metadata": {
        "id": "mSqUwNQJDeUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "UqRoE9kJDlsS"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making taining data\n",
        "# input (temp, rainfall, humidity)\n",
        "input = np.array([[73, 67, 43],\n",
        "                  [91, 88, 64],\n",
        "                  [87, 134, 58],\n",
        "                  [102, 43, 37],\n",
        "                  [69, 96, 70]], dtype='float32')"
      ],
      "metadata": {
        "id": "8FFrofWKDuIZ"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# targets (apple, oranges)\n",
        "target = np.array([[56, 70],\n",
        "                   [81, 101],\n",
        "                   [119, 133],\n",
        "                   [22, 37],\n",
        "                   [103, 119]], dtype='float32')"
      ],
      "metadata": {
        "id": "bYNPG0f1ErWD"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert input and target to tensors\n",
        "inputs  = torch.from_numpy(input)\n",
        "targets = torch.from_numpy(target)\n",
        "\n",
        "print(inputs,\"\\n\")\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylR5700iFC7U",
        "outputId": "ca0cbc71-db65-46fa-ed93-8e597a802c04"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]]) \n",
            "\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# weights and biases\n",
        "w = torch.randn(2,3, requires_grad=True)\n",
        "b = torch.randn(2, requires_grad=True)\n",
        "\n",
        "print(w)\n",
        "print(b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3MBoPEZFcwj",
        "outputId": "048c47f9-5e83-444a-de39-ac58b0bd4939"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.8579, -0.7527,  1.5819],\n",
            "        [-0.9530, -1.4692,  1.1312]], requires_grad=True)\n",
            "tensor([1.8834, 1.5916], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model and @ represent matrix mul:\n",
        "#w.t() is the transpose of the weight matrics.\n",
        "def model(x):\n",
        "  return x @ w.t() + b"
      ],
      "metadata": {
        "id": "4uA4ZXQMGK_r"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO109p8LHQ_3",
        "outputId": "8869641d-0f1b-4195-a6a2-a4a19b36aa6d"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  82.0994, -117.7754],\n",
            "        [ 114.9545, -142.0284],\n",
            "        [  67.4092, -212.5850],\n",
            "        [ 115.5498, -116.9407],\n",
            "        [  99.5518, -126.0277]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# actuall\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTb0frbLHYZY",
        "outputId": "32258bd4-7fbc-4eeb-d1bf-93b72ae406a2"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function MSE\n",
        "def MSE(actual,targets):\n",
        "  diff = actual - targets\n",
        "  return torch.sum(diff*diff) / diff.numel()\n"
      ],
      "metadata": {
        "id": "JpvkLaESITKr"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# error\n",
        "loss = MSE(targets, preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKugZu-rJGj5",
        "outputId": "ac070e52-cb74-4d10-ef41-df94a2dbf7de"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(31074.6875, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the gradient\n",
        "loss.backward()\n"
      ],
      "metadata": {
        "id": "rn64jNlhJVu5"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w, \"\\n\")\n",
        "print(w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrMX66yUJd5_",
        "outputId": "a87f6dfb-3a94-4774-e798-67fe3d95ff36"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.8579, -0.7527,  1.5819],\n",
            "        [-0.9530, -1.4692,  1.1312]], requires_grad=True) \n",
            "\n",
            "tensor([[  1962.1754,    303.0227,    704.6140],\n",
            "        [-19699.5879, -22083.5918, -13303.9668]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(b, \"\\b\")\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAQrBZOCJkBA",
        "outputId": "ec91cf62-31f2-4c7d-f396-7c71cb31487b"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.8834, 1.5916], requires_grad=True) \b\n",
            "tensor([  19.7130, -235.0714])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reset grad to iterate and and adjust the parameter\n",
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "\n",
        "print(w.grad)\n",
        "\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_28eDNBJxyU",
        "outputId": "50bea4a6-6587-4111-bd9f-1780a16ee225"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adjust params\n",
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BxosDYyKRVW",
        "outputId": "6f71c42c-f8a3-43f7-e649-d6f519a44af0"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  82.0994, -117.7754],\n",
            "        [ 114.9545, -142.0284],\n",
            "        [  67.4092, -212.5850],\n",
            "        [ 115.5498, -116.9407],\n",
            "        [  99.5518, -126.0277]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# losss\n",
        "loss = MSE(targets, preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpFYk5REKdQH",
        "outputId": "9431ecd5-dade-4863-9d00-1659255102c1"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(31074.6875, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "\n",
        "print(w.grad,\"\\n\")\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rq_4Wf7cK9js",
        "outputId": "32df76f5-0086-4c7d-8350-ebf9b6cfd898"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  1962.1754,    303.0227,    704.6140],\n",
            "        [-19699.5879, -22083.5918, -13303.9668]]) \n",
            "\n",
            "tensor([  19.7130, -235.0714])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adjust weight & reset grad\n",
        "with torch.no_grad():\n",
        "  w-=w.grad* 1e-5\n",
        "  b-=b.grad* 1e-5\n",
        "  w.grad.zero_()\n",
        "  b.grad.zero_()"
      ],
      "metadata": {
        "id": "sgILcTEgLC_P"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fgcw9MYzNj-n",
        "outputId": "d0a17eb4-8749-45f7-a5b5-1a83498c450d"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.8382, -0.7557,  1.5748],\n",
            "        [-0.7561, -1.2483,  1.2642]], requires_grad=True)\n",
            "tensor([1.8832, 1.5939], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate again\n",
        "preds= model(inputs)\n",
        "loss= MSE(targets, preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1yC4V9rNmSM",
        "outputId": "825a6c22-87e0-464b-826f-3a83f050a5ae"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(21447.2910, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# trainig for multiple epochs\n",
        "for i in range(400):\n",
        "  preds = model(inputs)\n",
        "  loss= MSE(targets,preds)\n",
        "  loss.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    w-=w.grad*1e-5\n",
        "    b-=b.grad*1e-5\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "  print(f\"EPOCHS({i}/{100}) & Loss {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sovohXc9N_yw",
        "outputId": "80f7f138-0f6f-4426-fa25-cdf2f4ecd6bd"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCHS(0/100) & Loss 21447.291015625\n",
            "EPOCHS(1/100) & Loss 3115.14306640625\n",
            "EPOCHS(2/100) & Loss 2576.42236328125\n",
            "EPOCHS(3/100) & Loss 2207.7822265625\n",
            "EPOCHS(4/100) & Loss 1953.8265380859375\n",
            "EPOCHS(5/100) & Loss 1777.224365234375\n",
            "EPOCHS(6/100) & Loss 1652.817626953125\n",
            "EPOCHS(7/100) & Loss 1563.65283203125\n",
            "EPOCHS(8/100) & Loss 1498.302490234375\n",
            "EPOCHS(9/100) & Loss 1449.0667724609375\n",
            "EPOCHS(10/100) & Loss 1410.7548828125\n",
            "EPOCHS(11/100) & Loss 1379.868896484375\n",
            "EPOCHS(12/100) & Loss 1354.0498046875\n",
            "EPOCHS(13/100) & Loss 1331.7081298828125\n",
            "EPOCHS(14/100) & Loss 1311.771240234375\n",
            "EPOCHS(15/100) & Loss 1293.515869140625\n",
            "EPOCHS(16/100) & Loss 1276.453857421875\n",
            "EPOCHS(17/100) & Loss 1260.2552490234375\n",
            "EPOCHS(18/100) & Loss 1244.6966552734375\n",
            "EPOCHS(19/100) & Loss 1229.6279296875\n",
            "EPOCHS(20/100) & Loss 1214.946044921875\n",
            "EPOCHS(21/100) & Loss 1200.58154296875\n",
            "EPOCHS(22/100) & Loss 1186.486083984375\n",
            "EPOCHS(23/100) & Loss 1172.627685546875\n",
            "EPOCHS(24/100) & Loss 1158.982666015625\n",
            "EPOCHS(25/100) & Loss 1145.535400390625\n",
            "EPOCHS(26/100) & Loss 1132.274658203125\n",
            "EPOCHS(27/100) & Loss 1119.191162109375\n",
            "EPOCHS(28/100) & Loss 1106.27880859375\n",
            "EPOCHS(29/100) & Loss 1093.533447265625\n",
            "EPOCHS(30/100) & Loss 1080.950439453125\n",
            "EPOCHS(31/100) & Loss 1068.5262451171875\n",
            "EPOCHS(32/100) & Loss 1056.2586669921875\n",
            "EPOCHS(33/100) & Loss 1044.1451416015625\n",
            "EPOCHS(34/100) & Loss 1032.1827392578125\n",
            "EPOCHS(35/100) & Loss 1020.3697509765625\n",
            "EPOCHS(36/100) & Loss 1008.7041015625\n",
            "EPOCHS(37/100) & Loss 997.1837768554688\n",
            "EPOCHS(38/100) & Loss 985.8068237304688\n",
            "EPOCHS(39/100) & Loss 974.5712890625\n",
            "EPOCHS(40/100) & Loss 963.4754638671875\n",
            "EPOCHS(41/100) & Loss 952.5177612304688\n",
            "EPOCHS(42/100) & Loss 941.6959228515625\n",
            "EPOCHS(43/100) & Loss 931.0086669921875\n",
            "EPOCHS(44/100) & Loss 920.4542236328125\n",
            "EPOCHS(45/100) & Loss 910.0308837890625\n",
            "EPOCHS(46/100) & Loss 899.7366333007812\n",
            "EPOCHS(47/100) & Loss 889.5703125\n",
            "EPOCHS(48/100) & Loss 879.5300903320312\n",
            "EPOCHS(49/100) & Loss 869.6146240234375\n",
            "EPOCHS(50/100) & Loss 859.8220825195312\n",
            "EPOCHS(51/100) & Loss 850.1510009765625\n",
            "EPOCHS(52/100) & Loss 840.5997924804688\n",
            "EPOCHS(53/100) & Loss 831.1668701171875\n",
            "EPOCHS(54/100) & Loss 821.85107421875\n",
            "EPOCHS(55/100) & Loss 812.6507568359375\n",
            "EPOCHS(56/100) & Loss 803.5643310546875\n",
            "EPOCHS(57/100) & Loss 794.5904541015625\n",
            "EPOCHS(58/100) & Loss 785.7277221679688\n",
            "EPOCHS(59/100) & Loss 776.974853515625\n",
            "EPOCHS(60/100) & Loss 768.3302612304688\n",
            "EPOCHS(61/100) & Loss 759.7926025390625\n",
            "EPOCHS(62/100) & Loss 751.360595703125\n",
            "EPOCHS(63/100) & Loss 743.0330200195312\n",
            "EPOCHS(64/100) & Loss 734.8084106445312\n",
            "EPOCHS(65/100) & Loss 726.6854248046875\n",
            "EPOCHS(66/100) & Loss 718.6629638671875\n",
            "EPOCHS(67/100) & Loss 710.7396240234375\n",
            "EPOCHS(68/100) & Loss 702.9142456054688\n",
            "EPOCHS(69/100) & Loss 695.185546875\n",
            "EPOCHS(70/100) & Loss 687.5521850585938\n",
            "EPOCHS(71/100) & Loss 680.0133056640625\n",
            "EPOCHS(72/100) & Loss 672.5673217773438\n",
            "EPOCHS(73/100) & Loss 665.2133178710938\n",
            "EPOCHS(74/100) & Loss 657.9500122070312\n",
            "EPOCHS(75/100) & Loss 650.7764892578125\n",
            "EPOCHS(76/100) & Loss 643.6912841796875\n",
            "EPOCHS(77/100) & Loss 636.6935424804688\n",
            "EPOCHS(78/100) & Loss 629.781982421875\n",
            "EPOCHS(79/100) & Loss 622.9556274414062\n",
            "EPOCHS(80/100) & Loss 616.2134399414062\n",
            "EPOCHS(81/100) & Loss 609.5542602539062\n",
            "EPOCHS(82/100) & Loss 602.9771118164062\n",
            "EPOCHS(83/100) & Loss 596.48095703125\n",
            "EPOCHS(84/100) & Loss 590.0647583007812\n",
            "EPOCHS(85/100) & Loss 583.7274169921875\n",
            "EPOCHS(86/100) & Loss 577.4681396484375\n",
            "EPOCHS(87/100) & Loss 571.285888671875\n",
            "EPOCHS(88/100) & Loss 565.1793823242188\n",
            "EPOCHS(89/100) & Loss 559.1482543945312\n",
            "EPOCHS(90/100) & Loss 553.1910400390625\n",
            "EPOCHS(91/100) & Loss 547.3070068359375\n",
            "EPOCHS(92/100) & Loss 541.4953002929688\n",
            "EPOCHS(93/100) & Loss 535.7550048828125\n",
            "EPOCHS(94/100) & Loss 530.0850219726562\n",
            "EPOCHS(95/100) & Loss 524.4847412109375\n",
            "EPOCHS(96/100) & Loss 518.9530029296875\n",
            "EPOCHS(97/100) & Loss 513.4891967773438\n",
            "EPOCHS(98/100) & Loss 508.09234619140625\n",
            "EPOCHS(99/100) & Loss 502.76165771484375\n",
            "EPOCHS(100/100) & Loss 497.49627685546875\n",
            "EPOCHS(101/100) & Loss 492.2953186035156\n",
            "EPOCHS(102/100) & Loss 487.15802001953125\n",
            "EPOCHS(103/100) & Loss 482.0835876464844\n",
            "EPOCHS(104/100) & Loss 477.07135009765625\n",
            "EPOCHS(105/100) & Loss 472.12030029296875\n",
            "EPOCHS(106/100) & Loss 467.2298278808594\n",
            "EPOCHS(107/100) & Loss 462.399169921875\n",
            "EPOCHS(108/100) & Loss 457.6275329589844\n",
            "EPOCHS(109/100) & Loss 452.9140625\n",
            "EPOCHS(110/100) & Loss 448.25811767578125\n",
            "EPOCHS(111/100) & Loss 443.65911865234375\n",
            "EPOCHS(112/100) & Loss 439.1163024902344\n",
            "EPOCHS(113/100) & Loss 434.6287536621094\n",
            "EPOCHS(114/100) & Loss 430.19580078125\n",
            "EPOCHS(115/100) & Loss 425.81707763671875\n",
            "EPOCHS(116/100) & Loss 421.49163818359375\n",
            "EPOCHS(117/100) & Loss 417.21881103515625\n",
            "EPOCHS(118/100) & Loss 412.99798583984375\n",
            "EPOCHS(119/100) & Loss 408.8284606933594\n",
            "EPOCHS(120/100) & Loss 404.7098083496094\n",
            "EPOCHS(121/100) & Loss 400.64117431640625\n",
            "EPOCHS(122/100) & Loss 396.62200927734375\n",
            "EPOCHS(123/100) & Loss 392.65155029296875\n",
            "EPOCHS(124/100) & Loss 388.72943115234375\n",
            "EPOCHS(125/100) & Loss 384.85491943359375\n",
            "EPOCHS(126/100) & Loss 381.02740478515625\n",
            "EPOCHS(127/100) & Loss 377.2463684082031\n",
            "EPOCHS(128/100) & Loss 373.51104736328125\n",
            "EPOCHS(129/100) & Loss 369.82098388671875\n",
            "EPOCHS(130/100) & Loss 366.1756591796875\n",
            "EPOCHS(131/100) & Loss 362.57452392578125\n",
            "EPOCHS(132/100) & Loss 359.0168762207031\n",
            "EPOCHS(133/100) & Loss 355.5023498535156\n",
            "EPOCHS(134/100) & Loss 352.03021240234375\n",
            "EPOCHS(135/100) & Loss 348.6000671386719\n",
            "EPOCHS(136/100) & Loss 345.2113342285156\n",
            "EPOCHS(137/100) & Loss 341.8635559082031\n",
            "EPOCHS(138/100) & Loss 338.5562438964844\n",
            "EPOCHS(139/100) & Loss 335.2887878417969\n",
            "EPOCHS(140/100) & Loss 332.06072998046875\n",
            "EPOCHS(141/100) & Loss 328.87152099609375\n",
            "EPOCHS(142/100) & Loss 325.7207336425781\n",
            "EPOCHS(143/100) & Loss 322.60791015625\n",
            "EPOCHS(144/100) & Loss 319.5324401855469\n",
            "EPOCHS(145/100) & Loss 316.49407958984375\n",
            "EPOCHS(146/100) & Loss 313.4922180175781\n",
            "EPOCHS(147/100) & Loss 310.5263671875\n",
            "EPOCHS(148/100) & Loss 307.5960998535156\n",
            "EPOCHS(149/100) & Loss 304.7011413574219\n",
            "EPOCHS(150/100) & Loss 301.8408203125\n",
            "EPOCHS(151/100) & Loss 299.0148010253906\n",
            "EPOCHS(152/100) & Loss 296.2225646972656\n",
            "EPOCHS(153/100) & Loss 293.4638671875\n",
            "EPOCHS(154/100) & Loss 290.7381286621094\n",
            "EPOCHS(155/100) & Loss 288.04510498046875\n",
            "EPOCHS(156/100) & Loss 285.38421630859375\n",
            "EPOCHS(157/100) & Loss 282.75506591796875\n",
            "EPOCHS(158/100) & Loss 280.1573181152344\n",
            "EPOCHS(159/100) & Loss 277.5906066894531\n",
            "EPOCHS(160/100) & Loss 275.0545349121094\n",
            "EPOCHS(161/100) & Loss 272.54864501953125\n",
            "EPOCHS(162/100) & Loss 270.0726013183594\n",
            "EPOCHS(163/100) & Loss 267.62603759765625\n",
            "EPOCHS(164/100) & Loss 265.2086486816406\n",
            "EPOCHS(165/100) & Loss 262.81988525390625\n",
            "EPOCHS(166/100) & Loss 260.4596252441406\n",
            "EPOCHS(167/100) & Loss 258.1273498535156\n",
            "EPOCHS(168/100) & Loss 255.82275390625\n",
            "EPOCHS(169/100) & Loss 253.5454864501953\n",
            "EPOCHS(170/100) & Loss 251.2952117919922\n",
            "EPOCHS(171/100) & Loss 249.07162475585938\n",
            "EPOCHS(172/100) & Loss 246.87429809570312\n",
            "EPOCHS(173/100) & Loss 244.70303344726562\n",
            "EPOCHS(174/100) & Loss 242.55734252929688\n",
            "EPOCHS(175/100) & Loss 240.43701171875\n",
            "EPOCHS(176/100) & Loss 238.3418426513672\n",
            "EPOCHS(177/100) & Loss 236.271240234375\n",
            "EPOCHS(178/100) & Loss 234.22512817382812\n",
            "EPOCHS(179/100) & Loss 232.2030792236328\n",
            "EPOCHS(180/100) & Loss 230.20486450195312\n",
            "EPOCHS(181/100) & Loss 228.23013305664062\n",
            "EPOCHS(182/100) & Loss 226.2786407470703\n",
            "EPOCHS(183/100) & Loss 224.3499755859375\n",
            "EPOCHS(184/100) & Loss 222.444091796875\n",
            "EPOCHS(185/100) & Loss 220.5603485107422\n",
            "EPOCHS(186/100) & Loss 218.6988067626953\n",
            "EPOCHS(187/100) & Loss 216.859130859375\n",
            "EPOCHS(188/100) & Loss 215.04086303710938\n",
            "EPOCHS(189/100) & Loss 213.24392700195312\n",
            "EPOCHS(190/100) & Loss 211.46792602539062\n",
            "EPOCHS(191/100) & Loss 209.71273803710938\n",
            "EPOCHS(192/100) & Loss 207.9779510498047\n",
            "EPOCHS(193/100) & Loss 206.26327514648438\n",
            "EPOCHS(194/100) & Loss 204.5687255859375\n",
            "EPOCHS(195/100) & Loss 202.8938446044922\n",
            "EPOCHS(196/100) & Loss 201.23843383789062\n",
            "EPOCHS(197/100) & Loss 199.60226440429688\n",
            "EPOCHS(198/100) & Loss 197.98501586914062\n",
            "EPOCHS(199/100) & Loss 196.3866424560547\n",
            "EPOCHS(200/100) & Loss 194.80667114257812\n",
            "EPOCHS(201/100) & Loss 193.24510192871094\n",
            "EPOCHS(202/100) & Loss 191.7014923095703\n",
            "EPOCHS(203/100) & Loss 190.17575073242188\n",
            "EPOCHS(204/100) & Loss 188.66758728027344\n",
            "EPOCHS(205/100) & Loss 187.1768341064453\n",
            "EPOCHS(206/100) & Loss 185.70321655273438\n",
            "EPOCHS(207/100) & Loss 184.24664306640625\n",
            "EPOCHS(208/100) & Loss 182.80682373046875\n",
            "EPOCHS(209/100) & Loss 181.38339233398438\n",
            "EPOCHS(210/100) & Loss 179.97640991210938\n",
            "EPOCHS(211/100) & Loss 178.58560180664062\n",
            "EPOCHS(212/100) & Loss 177.2106170654297\n",
            "EPOCHS(213/100) & Loss 175.85142517089844\n",
            "EPOCHS(214/100) & Loss 174.50779724121094\n",
            "EPOCHS(215/100) & Loss 173.17941284179688\n",
            "EPOCHS(216/100) & Loss 171.86630249023438\n",
            "EPOCHS(217/100) & Loss 170.56808471679688\n",
            "EPOCHS(218/100) & Loss 169.28466796875\n",
            "EPOCHS(219/100) & Loss 168.01585388183594\n",
            "EPOCHS(220/100) & Loss 166.76144409179688\n",
            "EPOCHS(221/100) & Loss 165.5213165283203\n",
            "EPOCHS(222/100) & Loss 164.2952117919922\n",
            "EPOCHS(223/100) & Loss 163.08299255371094\n",
            "EPOCHS(224/100) & Loss 161.884521484375\n",
            "EPOCHS(225/100) & Loss 160.69952392578125\n",
            "EPOCHS(226/100) & Loss 159.5279541015625\n",
            "EPOCHS(227/100) & Loss 158.36947631835938\n",
            "EPOCHS(228/100) & Loss 157.2241668701172\n",
            "EPOCHS(229/100) & Loss 156.0916748046875\n",
            "EPOCHS(230/100) & Loss 154.97195434570312\n",
            "EPOCHS(231/100) & Loss 153.86477661132812\n",
            "EPOCHS(232/100) & Loss 152.77005004882812\n",
            "EPOCHS(233/100) & Loss 151.68751525878906\n",
            "EPOCHS(234/100) & Loss 150.61709594726562\n",
            "EPOCHS(235/100) & Loss 149.55862426757812\n",
            "EPOCHS(236/100) & Loss 148.5120391845703\n",
            "EPOCHS(237/100) & Loss 147.47702026367188\n",
            "EPOCHS(238/100) & Loss 146.45352172851562\n",
            "EPOCHS(239/100) & Loss 145.4414520263672\n",
            "EPOCHS(240/100) & Loss 144.4406280517578\n",
            "EPOCHS(241/100) & Loss 143.45086669921875\n",
            "EPOCHS(242/100) & Loss 142.47201538085938\n",
            "EPOCHS(243/100) & Loss 141.50404357910156\n",
            "EPOCHS(244/100) & Loss 140.5467071533203\n",
            "EPOCHS(245/100) & Loss 139.60000610351562\n",
            "EPOCHS(246/100) & Loss 138.66360473632812\n",
            "EPOCHS(247/100) & Loss 137.737548828125\n",
            "EPOCHS(248/100) & Loss 136.8216552734375\n",
            "EPOCHS(249/100) & Loss 135.91590881347656\n",
            "EPOCHS(250/100) & Loss 135.01995849609375\n",
            "EPOCHS(251/100) & Loss 134.13388061523438\n",
            "EPOCHS(252/100) & Loss 133.2574462890625\n",
            "EPOCHS(253/100) & Loss 132.3905487060547\n",
            "EPOCHS(254/100) & Loss 131.5331573486328\n",
            "EPOCHS(255/100) & Loss 130.6849365234375\n",
            "EPOCHS(256/100) & Loss 129.8460693359375\n",
            "EPOCHS(257/100) & Loss 129.0162811279297\n",
            "EPOCHS(258/100) & Loss 128.19540405273438\n",
            "EPOCHS(259/100) & Loss 127.3833999633789\n",
            "EPOCHS(260/100) & Loss 126.58016204833984\n",
            "EPOCHS(261/100) & Loss 125.78564453125\n",
            "EPOCHS(262/100) & Loss 124.9996566772461\n",
            "EPOCHS(263/100) & Loss 124.22206115722656\n",
            "EPOCHS(264/100) & Loss 123.4528579711914\n",
            "EPOCHS(265/100) & Loss 122.69185638427734\n",
            "EPOCHS(266/100) & Loss 121.93904113769531\n",
            "EPOCHS(267/100) & Loss 121.1941909790039\n",
            "EPOCHS(268/100) & Loss 120.45735168457031\n",
            "EPOCHS(269/100) & Loss 119.72828674316406\n",
            "EPOCHS(270/100) & Loss 119.0069808959961\n",
            "EPOCHS(271/100) & Loss 118.29335021972656\n",
            "EPOCHS(272/100) & Loss 117.58723449707031\n",
            "EPOCHS(273/100) & Loss 116.8885269165039\n",
            "EPOCHS(274/100) & Loss 116.197265625\n",
            "EPOCHS(275/100) & Loss 115.51332092285156\n",
            "EPOCHS(276/100) & Loss 114.83647155761719\n",
            "EPOCHS(277/100) & Loss 114.16678619384766\n",
            "EPOCHS(278/100) & Loss 113.50407409667969\n",
            "EPOCHS(279/100) & Loss 112.84834289550781\n",
            "EPOCHS(280/100) & Loss 112.19941711425781\n",
            "EPOCHS(281/100) & Loss 111.5572738647461\n",
            "EPOCHS(282/100) & Loss 110.9217300415039\n",
            "EPOCHS(283/100) & Loss 110.29289245605469\n",
            "EPOCHS(284/100) & Loss 109.6705093383789\n",
            "EPOCHS(285/100) & Loss 109.0545883178711\n",
            "EPOCHS(286/100) & Loss 108.44500732421875\n",
            "EPOCHS(287/100) & Loss 107.84169006347656\n",
            "EPOCHS(288/100) & Loss 107.24458312988281\n",
            "EPOCHS(289/100) & Loss 106.65364837646484\n",
            "EPOCHS(290/100) & Loss 106.06874084472656\n",
            "EPOCHS(291/100) & Loss 105.48973083496094\n",
            "EPOCHS(292/100) & Loss 104.91676330566406\n",
            "EPOCHS(293/100) & Loss 104.34956359863281\n",
            "EPOCHS(294/100) & Loss 103.78812408447266\n",
            "EPOCHS(295/100) & Loss 103.23233795166016\n",
            "EPOCHS(296/100) & Loss 102.6822509765625\n",
            "EPOCHS(297/100) & Loss 102.13761901855469\n",
            "EPOCHS(298/100) & Loss 101.59857940673828\n",
            "EPOCHS(299/100) & Loss 101.06485748291016\n",
            "EPOCHS(300/100) & Loss 100.53660583496094\n",
            "EPOCHS(301/100) & Loss 100.01356506347656\n",
            "EPOCHS(302/100) & Loss 99.49581909179688\n",
            "EPOCHS(303/100) & Loss 98.98310089111328\n",
            "EPOCHS(304/100) & Loss 98.47564697265625\n",
            "EPOCHS(305/100) & Loss 97.97313690185547\n",
            "EPOCHS(306/100) & Loss 97.47561645507812\n",
            "EPOCHS(307/100) & Loss 96.9830093383789\n",
            "EPOCHS(308/100) & Loss 96.49525451660156\n",
            "EPOCHS(309/100) & Loss 96.01237487792969\n",
            "EPOCHS(310/100) & Loss 95.53410339355469\n",
            "EPOCHS(311/100) & Loss 95.06063079833984\n",
            "EPOCHS(312/100) & Loss 94.59169006347656\n",
            "EPOCHS(313/100) & Loss 94.12735748291016\n",
            "EPOCHS(314/100) & Loss 93.66761016845703\n",
            "EPOCHS(315/100) & Loss 93.2121810913086\n",
            "EPOCHS(316/100) & Loss 92.76127624511719\n",
            "EPOCHS(317/100) & Loss 92.31462860107422\n",
            "EPOCHS(318/100) & Loss 91.87237548828125\n",
            "EPOCHS(319/100) & Loss 91.43434143066406\n",
            "EPOCHS(320/100) & Loss 91.00050354003906\n",
            "EPOCHS(321/100) & Loss 90.57080078125\n",
            "EPOCHS(322/100) & Loss 90.14519500732422\n",
            "EPOCHS(323/100) & Loss 89.72364807128906\n",
            "EPOCHS(324/100) & Loss 89.3061294555664\n",
            "EPOCHS(325/100) & Loss 88.89250183105469\n",
            "EPOCHS(326/100) & Loss 88.48286437988281\n",
            "EPOCHS(327/100) & Loss 88.0769271850586\n",
            "EPOCHS(328/100) & Loss 87.67497253417969\n",
            "EPOCHS(329/100) & Loss 87.27664184570312\n",
            "EPOCHS(330/100) & Loss 86.88209533691406\n",
            "EPOCHS(331/100) & Loss 86.49125671386719\n",
            "EPOCHS(332/100) & Loss 86.10403442382812\n",
            "EPOCHS(333/100) & Loss 85.72040557861328\n",
            "EPOCHS(334/100) & Loss 85.34027862548828\n",
            "EPOCHS(335/100) & Loss 84.96366119384766\n",
            "EPOCHS(336/100) & Loss 84.59058380126953\n",
            "EPOCHS(337/100) & Loss 84.2208251953125\n",
            "EPOCHS(338/100) & Loss 83.85447692871094\n",
            "EPOCHS(339/100) & Loss 83.49148559570312\n",
            "EPOCHS(340/100) & Loss 83.1318359375\n",
            "EPOCHS(341/100) & Loss 82.77532196044922\n",
            "EPOCHS(342/100) & Loss 82.42219543457031\n",
            "EPOCHS(343/100) & Loss 82.07215118408203\n",
            "EPOCHS(344/100) & Loss 81.72526550292969\n",
            "EPOCHS(345/100) & Loss 81.38146209716797\n",
            "EPOCHS(346/100) & Loss 81.0407485961914\n",
            "EPOCHS(347/100) & Loss 80.70307159423828\n",
            "EPOCHS(348/100) & Loss 80.36841583251953\n",
            "EPOCHS(349/100) & Loss 80.03668975830078\n",
            "EPOCHS(350/100) & Loss 79.70791625976562\n",
            "EPOCHS(351/100) & Loss 79.3819808959961\n",
            "EPOCHS(352/100) & Loss 79.05897521972656\n",
            "EPOCHS(353/100) & Loss 78.73876190185547\n",
            "EPOCHS(354/100) & Loss 78.42135620117188\n",
            "EPOCHS(355/100) & Loss 78.10664367675781\n",
            "EPOCHS(356/100) & Loss 77.79478454589844\n",
            "EPOCHS(357/100) & Loss 77.48551177978516\n",
            "EPOCHS(358/100) & Loss 77.17890930175781\n",
            "EPOCHS(359/100) & Loss 76.87495422363281\n",
            "EPOCHS(360/100) & Loss 76.57362365722656\n",
            "EPOCHS(361/100) & Loss 76.2748794555664\n",
            "EPOCHS(362/100) & Loss 75.97863006591797\n",
            "EPOCHS(363/100) & Loss 75.68489837646484\n",
            "EPOCHS(364/100) & Loss 75.3936767578125\n",
            "EPOCHS(365/100) & Loss 75.10487365722656\n",
            "EPOCHS(366/100) & Loss 74.81852722167969\n",
            "EPOCHS(367/100) & Loss 74.53450775146484\n",
            "EPOCHS(368/100) & Loss 74.25292205810547\n",
            "EPOCHS(369/100) & Loss 73.97372436523438\n",
            "EPOCHS(370/100) & Loss 73.69674682617188\n",
            "EPOCHS(371/100) & Loss 73.42207336425781\n",
            "EPOCHS(372/100) & Loss 73.149658203125\n",
            "EPOCHS(373/100) & Loss 72.87947082519531\n",
            "EPOCHS(374/100) & Loss 72.61146545410156\n",
            "EPOCHS(375/100) & Loss 72.34567260742188\n",
            "EPOCHS(376/100) & Loss 72.08204650878906\n",
            "EPOCHS(377/100) & Loss 71.82050323486328\n",
            "EPOCHS(378/100) & Loss 71.56118774414062\n",
            "EPOCHS(379/100) & Loss 71.3038558959961\n",
            "EPOCHS(380/100) & Loss 71.0485610961914\n",
            "EPOCHS(381/100) & Loss 70.79534149169922\n",
            "EPOCHS(382/100) & Loss 70.54410552978516\n",
            "EPOCHS(383/100) & Loss 70.29491424560547\n",
            "EPOCHS(384/100) & Loss 70.04763793945312\n",
            "EPOCHS(385/100) & Loss 69.80229949951172\n",
            "EPOCHS(386/100) & Loss 69.55892944335938\n",
            "EPOCHS(387/100) & Loss 69.31739807128906\n",
            "EPOCHS(388/100) & Loss 69.0777587890625\n",
            "EPOCHS(389/100) & Loss 68.8399429321289\n",
            "EPOCHS(390/100) & Loss 68.6040267944336\n",
            "EPOCHS(391/100) & Loss 68.36985778808594\n",
            "EPOCHS(392/100) & Loss 68.13749694824219\n",
            "EPOCHS(393/100) & Loss 67.90690612792969\n",
            "EPOCHS(394/100) & Loss 67.67813873291016\n",
            "EPOCHS(395/100) & Loss 67.45105743408203\n",
            "EPOCHS(396/100) & Loss 67.22565460205078\n",
            "EPOCHS(397/100) & Loss 67.00193786621094\n",
            "EPOCHS(398/100) & Loss 66.77989196777344\n",
            "EPOCHS(399/100) & Loss 66.55955505371094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs)\n",
        "loss = MSE(targets,preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q26fqACAO_Uv",
        "outputId": "180c1c9b-2308-4f11-bf28-dd9c3958b2f8"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(66.3408, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "sqrt(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XtN015eR8w1",
        "outputId": "f6465ec2-bef3-4840-ceed-aa8b25c9947f"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.144986498068056"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sc4AI1EUSFof",
        "outputId": "52b2af29-c3e0-474a-8567-54e53919b342"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 58.0239,  70.5234],\n",
              "        [ 88.1537, 106.3848],\n",
              "        [103.7933, 119.6219],\n",
              "        [ 24.7945,  37.2687],\n",
              "        [110.4682, 129.2467]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAbC-lj5SIKN",
        "outputId": "871d8521-d0b9-4479-f473-8ab464be5e14"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Network using pytorch"
      ],
      "metadata": {
        "id": "WF8b5r3SSTX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to check gpu\n",
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4i9YznJtSLNw",
        "outputId": "008dd802-dfef-46a1-c87a-78583777ce90"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Mar  3 11:18:28 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "metadata": {
        "id": "BqsUVjxdSfQK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download trainig data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "     root = \"data\",\n",
        "     train=True,\n",
        "     download=True,\n",
        "     transform=ToTensor(),\n",
        " )\n",
        "# download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJMN1lPsEpSf",
        "outputId": "a2ced1f8-9827-4498-c792-ad70ad3cef9c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 14938822.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 270707.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5003756.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 5165616.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "KLQkVNhZFjoj",
        "outputId": "11150e1d-c363-4373-83f2-a274f3157581"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchvision.datasets.mnist.FashionMNIST"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torchvision.datasets.mnist.FashionMNIST</b><br/>def __init__(root: str, train: bool=True, transform: Optional[Callable]=None, target_transform: Optional[Callable]=None, download: bool=False) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py</a>`Fashion-MNIST &lt;https://github.com/zalandoresearch/fashion-mnist&gt;`_ Dataset.\n",
              "\n",
              "Args:\n",
              "    root (string): Root directory of dataset where ``FashionMNIST/raw/train-images-idx3-ubyte``\n",
              "        and  ``FashionMNIST/raw/t10k-images-idx3-ubyte`` exist.\n",
              "    train (bool, optional): If True, creates dataset from ``train-images-idx3-ubyte``,\n",
              "        otherwise from ``t10k-images-idx3-ubyte``.\n",
              "    download (bool, optional): If True, downloads the dataset from the internet and\n",
              "        puts it in root directory. If dataset is already downloaded, it is not\n",
              "        downloaded again.\n",
              "    transform (callable, optional): A function/transform that  takes in an PIL image\n",
              "        and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
              "    target_transform (callable, optional): A function/transform that takes in the\n",
              "        target and transforms it.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 202);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# create data loaders\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "  print(\"shape of x [N, C, H, W] : \", X.shape)\n",
        "  print(\"shape of y: \", y.shape, y.dtype)\n",
        "  #print(X)\n",
        "  #print(y)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9DO_4EAgDvN",
        "outputId": "8c65098f-99a5-4d28-dd2c-f1abf4140fa7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of x [N, C, H, W] :  torch.Size([64, 1, 28, 28])\n",
            "shape of y:  torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get cpu or gpu device for training .\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_KtwblYgKWO",
        "outputId": "266ae2f9-4c3a-47e8-a11f-75a951c54808"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 10)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zo7gddKehnnm",
        "outputId": "efc32711-974d-4607-8e33-76fa7fec124a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "zJIaYwqqjSEa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # compute prediciton error\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred,y)\n",
        "\n",
        "    ## backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 100 ==0:\n",
        "       loss, current = loss.item(), batch*len(X)\n",
        "       print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "JnbDI27FkBs-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss+= loss_fn(pred, y).item()\n",
        "      correct+= (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"test error: \\n accuracy: {(100*correct):>0.1f}%, avg loss: {test_loss:>8f}  \\n\")\n"
      ],
      "metadata": {
        "id": "v2HL5IOABWqo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "  print(f\"epochs {t+1} \\n------------------------\")\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\n",
        "  test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw9zN4itDLVu",
        "outputId": "0c57077d-d4ec-4047-d691-110118cde98e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epochs 1 \n",
            "------------------------\n",
            "loss: 2.313877 [    0/60000]\n",
            "loss: 2.301392 [ 6400/60000]\n",
            "loss: 2.287796 [12800/60000]\n",
            "loss: 2.273641 [19200/60000]\n",
            "loss: 2.245208 [25600/60000]\n",
            "loss: 2.228336 [32000/60000]\n",
            "loss: 2.242168 [38400/60000]\n",
            "loss: 2.208712 [44800/60000]\n",
            "loss: 2.200169 [51200/60000]\n",
            "loss: 2.170342 [57600/60000]\n",
            "test error: \n",
            " accuracy: 35.2%, avg loss: 2.165783  \n",
            "\n",
            "epochs 2 \n",
            "------------------------\n",
            "loss: 2.176294 [    0/60000]\n",
            "loss: 2.171599 [ 6400/60000]\n",
            "loss: 2.123012 [12800/60000]\n",
            "loss: 2.135499 [19200/60000]\n",
            "loss: 2.082360 [25600/60000]\n",
            "loss: 2.025422 [32000/60000]\n",
            "loss: 2.067966 [38400/60000]\n",
            "loss: 1.985907 [44800/60000]\n",
            "loss: 1.987984 [51200/60000]\n",
            "loss: 1.933740 [57600/60000]\n",
            "test error: \n",
            " accuracy: 52.8%, avg loss: 1.924941  \n",
            "\n",
            "epochs 3 \n",
            "------------------------\n",
            "loss: 1.946632 [    0/60000]\n",
            "loss: 1.935398 [ 6400/60000]\n",
            "loss: 1.827363 [12800/60000]\n",
            "loss: 1.870585 [19200/60000]\n",
            "loss: 1.765755 [25600/60000]\n",
            "loss: 1.700105 [32000/60000]\n",
            "loss: 1.744616 [38400/60000]\n",
            "loss: 1.627067 [44800/60000]\n",
            "loss: 1.657194 [51200/60000]\n",
            "loss: 1.569831 [57600/60000]\n",
            "test error: \n",
            " accuracy: 59.3%, avg loss: 1.570959  \n",
            "\n",
            "epochs 4 \n",
            "------------------------\n",
            "loss: 1.619954 [    0/60000]\n",
            "loss: 1.600772 [ 6400/60000]\n",
            "loss: 1.453596 [12800/60000]\n",
            "loss: 1.533593 [19200/60000]\n",
            "loss: 1.408306 [25600/60000]\n",
            "loss: 1.383877 [32000/60000]\n",
            "loss: 1.416306 [38400/60000]\n",
            "loss: 1.321286 [44800/60000]\n",
            "loss: 1.367320 [51200/60000]\n",
            "loss: 1.273848 [57600/60000]\n",
            "test error: \n",
            " accuracy: 63.0%, avg loss: 1.289387  \n",
            "\n",
            "epochs 5 \n",
            "------------------------\n",
            "loss: 1.353763 [    0/60000]\n",
            "loss: 1.345417 [ 6400/60000]\n",
            "loss: 1.186180 [12800/60000]\n",
            "loss: 1.296127 [19200/60000]\n",
            "loss: 1.161704 [25600/60000]\n",
            "loss: 1.175908 [32000/60000]\n",
            "loss: 1.207569 [38400/60000]\n",
            "loss: 1.130381 [44800/60000]\n",
            "loss: 1.179692 [51200/60000]\n",
            "loss: 1.100286 [57600/60000]\n",
            "test error: \n",
            " accuracy: 64.6%, avg loss: 1.111231  \n",
            "\n",
            "Done!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"saved pytorch model state to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5FMy08VDtMl",
        "outputId": "69497865-65f6-4088-a367-99ecc99b2ce8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved pytorch model state to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load model  (yaha per agar hume data set or koi mille to bs apne save kiye hue data ko lena hae and ussi pe train karna hae)\n",
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ert1-AJYEpCE",
        "outputId": "7ff00d5f-1549-405d-8f23-05908ea73aef"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### prediction\n",
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "  pred = model(x)\n",
        "  predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "  print(f'Predicted: \"{predicted}\", actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3_Whr_bFBdq",
        "outputId": "c81f9058-363b-44c6-ee31-94cd214619d5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"ankle boot\", actual: \"ankle boot\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8xEcjNAyAPrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KJS44r9eGGGX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}